{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import json\n",
    "import pymorphy2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.json', 'r',encoding='utf-8') as file:\n",
    "    sentences = json.load(file)\n",
    "sentences = [elem['text'] for elem in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Папка, где хранятся ваши txt файлы\n",
    "data_folder = 'c:\\\\Users\\\\warpa\\\\Synonyms'\n",
    "\n",
    "# Создадим пустой словарь для хранения данных\n",
    "synonym_tables = {}\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(data_folder, filename), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                # Разделим строку на слово и его синонимы\n",
    "                word, synonyms = line.split('[')\n",
    "                word = word.strip(',').lower()\n",
    "                synonyms = [s.strip(' \\'').lower() for s in synonyms.split(']')[0].split(',')]\n",
    "\n",
    "                # Определим первую букву слова\n",
    "                first_letter = word[0].lower()\n",
    "\n",
    "                # Если буква уже есть в таблице, добавим слово и синонимы\n",
    "                if first_letter in synonym_tables:\n",
    "                    if word in synonym_tables[first_letter]:\n",
    "                        synonym_tables[first_letter][word].extend(synonyms)\n",
    "                    else:\n",
    "                        synonym_tables[first_letter][word] = synonyms\n",
    "                else:\n",
    "                    # В противном случае, создадим новую хэш-таблицу\n",
    "                    synonym_tables[first_letter] = {word: synonyms}\n",
    "\n",
    "# Пример использования таблицы для слов на букву 'а'\n",
    "if 'а' in synonym_tables:\n",
    "    print(synonym_tables['к'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_sentence(sentence, word_set, synonym_tables):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    sentence = replace_unknown_words(sentence, word_set, synonym_tables)\n",
    "    sentence = replace_pronouns(sentence)\n",
    "    sentence = replace_prepositions(sentence)\n",
    "    sentence = lemmatize_sentence(sentence)\n",
    "    return sentence\n",
    "\n",
    "def find_synonyms_in_table(sentence, synonym_tables):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    words = sentence.lower().split()\n",
    "    synonyms_dict = {}\n",
    "\n",
    "    for word in words:\n",
    "        normalized_word = morph.parse(word)[0].normal_form\n",
    "        letter = normalized_word[0].lower()\n",
    "\n",
    "        if letter in synonym_tables:\n",
    "            if normalized_word in synonym_tables[letter]:\n",
    "                synonyms = synonym_tables[letter][normalized_word]\n",
    "                synonyms_dict[word] = synonyms\n",
    "\n",
    "    return synonyms_dict\n",
    "\n",
    "\n",
    "def compare_sentences_with_synonyms(sentence1, sentence2, synonym_tables):\n",
    "    synonyms_dict1 = find_synonyms_in_table(sentence1, synonym_tables)\n",
    "    \n",
    "    synonyms_dict2 = find_synonyms_in_table(sentence2, synonym_tables)\n",
    "    \n",
    "    for word1, synonyms1 in synonyms_dict1.items():\n",
    "        for word2 in sentence2.split():\n",
    "            if word1 == word2 or any(word2 in synonyms1 for synonym in synonyms1):\n",
    "                sentence1 = sentence1.replace(word1, word2)\n",
    "                \n",
    "    return sentence1, sentence2\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    return ' '.join([morph.parse(word)[0].normal_form for word in sentence.split()])\n",
    "\n",
    "def compare_sentences(words1, words2, synonym_tables):\n",
    "    lemmas1 = set(words1.split())\n",
    "    lemmas2 = set(words2.split())\n",
    "    \n",
    "    # Получаем предложения с учетом синонимов\n",
    "    sentence1, sentence2 = compare_sentences_with_synonyms(words1, words2, synonym_tables)\n",
    "\n",
    "    # Получаем множество слов в предложениях с учетом синонимов\n",
    "    lemmas1_synonyms = set(sentence1.split())\n",
    "    lemmas2_synonyms = set(sentence2.split())\n",
    "   \n",
    "\n",
    "    common_words = lemmas1_synonyms & lemmas2_synonyms\n",
    "\n",
    "    common_words_synonyms = set()\n",
    "    for word in common_words:\n",
    "        if word in synonym_tables:\n",
    "            common_words_synonyms.update(synonym_tables[word])\n",
    "    \n",
    "    total_words = lemmas1_synonyms.union(lemmas2_synonyms).union(common_words_synonyms)\n",
    "\n",
    "    similarity = len(common_words) / len(total_words) if len(total_words) > 0 else 0\n",
    "\n",
    "    if ('не' in lemmas1 and 'не' in lemmas2) or ('не' not in lemmas1 and 'не' not in lemmas2):\n",
    "        similarity *= 1\n",
    "    else:\n",
    "        similarity = similarity - 0.3\n",
    "\n",
    "    parsed_words1 = [morph.parse(word)[0].normal_form for word in sentence1.split() if morph.parse(word)[0].tag.POS in ('VERB', 'INFN')]\n",
    "    parsed_words2 = [morph.parse(word)[0].normal_form for word in sentence2.split() if morph.parse(word)[0].tag.POS in ('VERB', 'INFN')]\n",
    "\n",
    "    if set(parsed_words2) != set(parsed_words1):\n",
    "        similarity = similarity - 0.3\n",
    "    else:\n",
    "        similarity = similarity\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def replace_pronouns(sentence):\n",
    "    return ' '.join(['<PRONOUN>' if 'NPRO' in morph.parse(word)[0].tag else word for word in sentence.split()])\n",
    "\n",
    "def replace_prepositions(sentence, replacement_token='PREPOSITION'):\n",
    "    return ' '.join([replacement_token if 'PREP' in morph.parse(word)[0].tag else word for word in sentence.split()])\n",
    "\n",
    "def levenshtein_distance(first_word, second_word):\n",
    "    if len(first_word) < len(second_word):\n",
    "        return levenshtein_distance(second_word, first_word)\n",
    "\n",
    "    if len(second_word) == 0:\n",
    "        return len(first_word)\n",
    "\n",
    "    previous_row = list(range(len(second_word) + 1))\n",
    "\n",
    "    for i, c1 in enumerate(first_word):\n",
    "        current_row = [i + 1]\n",
    "\n",
    "        for j, c2 in enumerate(second_word):\n",
    "            # Calculate insertions, deletions and substitutions\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "\n",
    "            # Get the minimum to append to the current row\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "\n",
    "        # Store the previous row\n",
    "        previous_row = current_row\n",
    "\n",
    "    # Returns the last element (distance)\n",
    "    return previous_row[-1]\n",
    "\n",
    "def find_similar(s1, arr):\n",
    "    for j in range(8):\n",
    "        for word in arr:\n",
    "            if levenshtein_distance(s1, word) <= j:\n",
    "                return word\n",
    "\n",
    "def replace_unknown_words(sentence, word_set, synonym_tables):\n",
    "    words = sentence.split()\n",
    "    corrected_sentence = []\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        parsed_word = morph.parse(word)[0]\n",
    "        \n",
    "        if \"UnknownPrefixAnalyzer\" in str(parsed_word.methods_stack):\n",
    "            # Убираем слово с ошибкой из множества перед поиском наиболее похожего\n",
    "            word_set_without_error = word_set - {word}\n",
    "            \n",
    "            # Найдем ближайшее слово из множества и заменим\n",
    "            corrected_word = find_similar(word, word_set_without_error)\n",
    "            \n",
    "            words[i] = corrected_word\n",
    "            corrected_sentence.append(f\"{word} -> {corrected_word}\")\n",
    "        else:\n",
    "            corrected_sentence.append(word)\n",
    "\n",
    "    return ' '.join(corrected_sentence)\n",
    "\n",
    "# Создаем множество всех слов в предложениях\n",
    "# sentences = {\"Я люблю кушать\",\"я люблю есть\"}\n",
    "all_words_set = set(word for sentence in sentences for word in sentence.split())\n",
    "\n",
    "# Создайте пустой словарь для хранения сходства между предложениями\n",
    "similarity_matrix = {}\n",
    "\n",
    "preprocessed_sentences = [preprocess_sentence(sentence, all_words_set, synonym_tables) for sentence in sentences]\n",
    "\n",
    "# Используем TF-IDF векторизацию\n",
    "# vectorizer = TfidfVectorizer(analyzer=lambda x: x.split())\n",
    "# tfidf_matrix = vectorizer.fit_transform(preprocessed_sentences)\n",
    "\n",
    "# Сравните все пары предложений в датасете\n",
    "for i in tqdm(range(len(preprocessed_sentences))):\n",
    "    for j in range(i+1, len(preprocessed_sentences)):\n",
    "        similarity = compare_sentences(preprocessed_sentences[i], preprocessed_sentences[j], synonym_tables)\n",
    "        similarity_matrix[(i, j)] = similarity\n",
    "\n",
    "# Выведите результаты сходства между парами предложений\n",
    "for (i, j), similarity in similarity_matrix.items():\n",
    "    print(f\"Сходство между предложением {i + 1} и предложением {j + 1}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_sentence(sentence, word_set, synonym_tables):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    sentence = replace_unknown_words(sentence, word_set, synonym_tables)\n",
    "    sentence = replace_pronouns(sentence)\n",
    "    sentence = replace_prepositions(sentence)\n",
    "    sentence = lemmatize_sentence(sentence)\n",
    "    return sentence\n",
    "\n",
    "def find_synonyms_in_table(sentence, synonym_tables):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    words = sentence.lower().split()\n",
    "    synonyms_dict = {}\n",
    "\n",
    "    for word in words:\n",
    "        normalized_word = morph.parse(word)[0].normal_form\n",
    "        letter = normalized_word[0].lower()\n",
    "\n",
    "        if letter in synonym_tables and normalized_word in synonym_tables[letter]:\n",
    "            synonyms = synonym_tables[letter][normalized_word]\n",
    "            synonyms_dict[word] = synonyms\n",
    "\n",
    "    return synonyms_dict\n",
    "\n",
    "def compare_sentences_with_synonyms(sentence1, sentence2, synonym_tables):\n",
    "    synonyms_dict1 = find_synonyms_in_table(sentence1, synonym_tables)\n",
    "    synonyms_dict2 = find_synonyms_in_table(sentence2, synonym_tables)\n",
    "\n",
    "    for word1, synonyms1 in synonyms_dict1.items():\n",
    "        for word2 in sentence2.split():\n",
    "            if word1 == word2 or any(word2 in synonyms1 for synonym in synonyms1):\n",
    "                sentence1 = sentence1.replace(word1, word2)\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    return ' '.join([morph.parse(word)[0].normal_form for word in sentence.split()])\n",
    "\n",
    "def compare_sentences(words1, words2, synonym_tables):\n",
    "    # Получаем предложения с учетом синонимов\n",
    "    sentence1, sentence2 = compare_sentences_with_synonyms(words1, words2, synonym_tables)\n",
    "\n",
    "    lemmas1 = set(sentence1.split())\n",
    "    lemmas2 = set(sentence2.split())\n",
    "\n",
    "    common_words = lemmas1 & lemmas2\n",
    "\n",
    "    common_words_synonyms = set()\n",
    "    for word in common_words:\n",
    "        if word in synonym_tables:\n",
    "            common_words_synonyms.update(synonym_tables[word])\n",
    "\n",
    "    total_words = lemmas1.union(lemmas2).union(common_words_synonyms)\n",
    "\n",
    "    similarity = len(common_words) / len(total_words) if len(total_words) > 0 else 0\n",
    "\n",
    "    if ('не' in lemmas1 and 'не' in lemmas2) or ('не' not in lemmas1 and 'не' not in lemmas2):\n",
    "        similarity *= 1\n",
    "    else:\n",
    "        similarity = similarity - 0.3\n",
    "\n",
    "    parsed_words1 = [morph.parse(word)[0].normal_form for word in sentence1.split() if morph.parse(word)[0].tag.POS in ('VERB', 'INFN')]\n",
    "    parsed_words2 = [morph.parse(word)[0].normal_form for word in sentence2.split() if morph.parse(word)[0].tag.POS in ('VERB', 'INFN')]\n",
    "\n",
    "    if set(parsed_words2) != set(parsed_words1):\n",
    "        similarity = similarity - 0.3\n",
    "    else:\n",
    "        similarity = similarity\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Создаем множество всех слов в предложениях\n",
    "all_words_set = set(word for sentence in sentences for word in sentence.split())\n",
    "\n",
    "# Создайте пустой словарь для хранения сходства между предложениями\n",
    "similarity_matrix = {}\n",
    "\n",
    "preprocessed_sentences = [preprocess_sentence(sentence, all_words_set, synonym_tables) for sentence in sentences]\n",
    "\n",
    "# Сравните все пары предложений в датасете\n",
    "for i in tqdm(range(len(preprocessed_sentences))):\n",
    "    for j in range(i+1, len(preprocessed_sentences)):\n",
    "        similarity = compare_sentences(preprocessed_sentences[i], preprocessed_sentences[j], synonym_tables)\n",
    "        similarity_matrix[(i, j)] = similarity\n",
    "\n",
    "# Выведите результаты сходства между парами предложений\n",
    "for (i, j), similarity in similarity_matrix.items():\n",
    "    print(f\"Сходство между предложением {i + 1} и предложением {j + 1}: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = [(i, j,similarity ) for (i, j), similarity in similarity_matrix.items() if 0.4<similarity<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, similarity in sim:\n",
    "    sentence1 = sentences[i]\n",
    "    sentence2 = sentences[j]\n",
    "    print(f\"Похожие предложения (сходство {similarity:.2f}):\")\n",
    "    print(f\"{sentence1}\")\n",
    "    print(f\"{sentence2}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
